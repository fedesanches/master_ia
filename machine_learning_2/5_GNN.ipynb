{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip -q install torch torch_geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dditmwVsrxmb",
        "outputId": "0cad70e1-c38f-469f-bd2c-dd58b1af9165"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, random, numpy as np, torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.nn import GCNConv\n",
        "import torch_geometric.transforms as T"
      ],
      "metadata": {
        "id": "MfW0lhpPrxjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------\n",
        "# 0) Config y reproducibilidad\n",
        "# --------------------------\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Device:\", device)\n",
        "\n",
        "# Hiperparámetros\n",
        "HIDDEN_DIM = 16\n",
        "DROPOUT    = 0.5\n",
        "LR         = 0.01\n",
        "WEIGHT_DEC = 5e-4\n",
        "EPOCHS     = 200"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Vfc9EAbrxfQ",
        "outputId": "60921e1f-370b-4481-a0ca-f6f886222ad7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------\n",
        "# 1) Dataset: Cora (Planetoid)\n",
        "#    Incluye máscaras de train/val/test\n",
        "#    Normalizamos features por nodo\n",
        "# --------------------------\n",
        "root = \"data/Planetoid\"\n",
        "dataset = Planetoid(root=root, name=\"Cora\", transform=T.NormalizeFeatures())\n",
        "data = dataset[0].to(device)  # Un único grafo con x, edge_index, y, train_mask, val_mask, test_mask\n",
        "\n",
        "print(f\"#Nodos: {data.num_nodes}  | #Aristas: {data.num_edges}  | #Features: {dataset.num_features}  | #Clases: {dataset.num_classes}\")\n",
        "print(f\"Máscaras -> train: {int(data.train_mask.sum())}, val: {int(data.val_mask.sum())}, test: {int(data.test_mask.sum())}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsOM7aU7rxcg",
        "outputId": "9c17603f-45cd-4169-93bd-e18673b18811"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
            "Processing...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#Nodos: 2708  | #Aristas: 10556  | #Features: 1433  | #Clases: 7\n",
            "Máscaras -> train: 140, val: 500, test: 1000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------\n",
        "# 2) Modelo GCN (2 capas)\n",
        "# --------------------------\n",
        "class GCN(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim, out_dim, dropout=0.5):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_dim, hidden_dim)\n",
        "        self.conv2 = GCNConv(hidden_dim, out_dim)\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)   # Mensajería en el grafo\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "model = GCN(dataset.num_features, HIDDEN_DIM, dataset.num_classes, DROPOUT).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DEC)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "yVq3eiNcrxZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------\n",
        "# 3) Utilidades de accuracy en máscaras (nodos)\n",
        "# --------------------------\n",
        "@torch.no_grad()\n",
        "def masked_accuracy(logits, y, mask):\n",
        "    preds = logits.argmax(dim=1)\n",
        "    correct = (preds[mask] == y[mask]).sum().item()\n",
        "    total = int(mask.sum())\n",
        "    return 100.0 * correct / total"
      ],
      "metadata": {
        "id": "jds3WM_WrxXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------\n",
        "# 4) Entrenamiento\n",
        "# --------------------------\n",
        "best_val_acc, best_state = 0.0, None\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data.x, data.edge_index)          # [N, C]\n",
        "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Eval\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        logits = model(data.x, data.edge_index)\n",
        "        train_acc = masked_accuracy(logits, data.y, data.train_mask)\n",
        "        val_acc   = masked_accuracy(logits, data.y, data.val_mask)\n",
        "        test_acc  = masked_accuracy(logits, data.y, data.test_mask)\n",
        "\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
        "\n",
        "    if epoch % 20 == 0 or epoch == 1:\n",
        "        print(f\"[{epoch:03d}] loss={loss.item():.4f} | train={train_acc:.2f}% | val={val_acc:.2f}% | test={test_acc:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcu7AwXIrxUN",
        "outputId": "dc903ba4-f5c4-4bac-c272-6355f1e624a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[001] loss=1.9459 | train=32.14% | val=14.40% | test=15.70%\n",
            "[020] loss=1.7174 | train=85.71% | val=52.60% | test=53.60%\n",
            "[040] loss=1.3281 | train=96.43% | val=70.40% | test=70.30%\n",
            "[060] loss=0.9540 | train=99.29% | val=76.00% | test=77.20%\n",
            "[080] loss=0.6925 | train=99.29% | val=77.60% | test=79.00%\n",
            "[100] loss=0.5591 | train=99.29% | val=76.60% | test=79.50%\n",
            "[120] loss=0.4700 | train=99.29% | val=77.40% | test=80.20%\n",
            "[140] loss=0.4071 | train=99.29% | val=77.80% | test=80.10%\n",
            "[160] loss=0.3849 | train=100.00% | val=77.80% | test=80.10%\n",
            "[180] loss=0.3435 | train=100.00% | val=77.80% | test=80.20%\n",
            "[200] loss=0.3223 | train=100.00% | val=78.00% | test=79.90%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ejercicios:\n",
        "1) Agregar early stopping.\n",
        "2) Comparar GCNConv con GraphSAGE, Message Passing y GAT.\n",
        "3) Comparar la performance en distintos datasets: Cora, CiteSeer, PubMed, etc."
      ],
      "metadata": {
        "id": "ZCwWv8vOsSSb"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-12BmzXDsR8H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}